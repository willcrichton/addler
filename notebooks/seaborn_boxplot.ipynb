{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn boxplot inliner example\n",
    "\n",
    "This notebook shows a more complex inlining sequence for the Seaborn boxplot API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T23:56:22.058521Z",
     "start_time": "2020-12-10T23:56:22.034357Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T23:56:23.051882Z",
     "start_time": "2020-12-10T23:56:22.484405Z"
    }
   },
   "outputs": [],
   "source": [
    "from inliner import Inliner\n",
    "from inliner.targets import make_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T23:56:25.423130Z",
     "start_time": "2020-12-10T23:56:24.180718Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import lux\n",
    "from lux.vis.Vis import Vis\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:20:02.382439Z",
     "start_time": "2020-12-11T00:19:46.977553Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import warnings\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from lux.core.frame import LuxDataFrame\n",
      "from lux.executor.PandasExecutor import PandasExecutor\n",
      "from lux.processor.Compiler import Compiler\n",
      "from lux.processor.Parser import Parser\n",
      "from lux.processor.Validator import Validator\n",
      "from lux.utils import date_utils, utils\n",
      "from lux.utils.date_utils import is_datetime_series, is_datetime_string\n",
      "from lux.vis import Clause\n",
      "from lux.vis.Clause import Clause\n",
      "from lux.vis.VisList import VisList\n",
      "from pandas.core.frame import DataFrame\n",
      "\n",
      "Vis_ret = Vis.__new__(Vis)\n",
      "\n",
      "# Vis(Vis_ret, ['sepal_length'], iris)\n",
      "intent = ['sepal_length']\n",
      "title = \"\"\n",
      "score = 0.0\n",
      "Vis_ret._intent = intent  # This is the user's original intent to Vis\n",
      "Vis_ret._inferred_intent = intent  # This is the re-written, expanded version of user's original intent (include inferred vis info)\n",
      "Vis_ret._source = iris  # This is the original data that is attached to the Vis\n",
      "Vis_ret._vis_data = (\n",
      "    None  # This is the data that represents the Vis (e.g., selected, aggregated, binned)\n",
      ")\n",
      "Vis_ret._code = None\n",
      "Vis_ret._mark = \"\"\n",
      "Vis_ret._min_max = {}\n",
      "Vis_ret._postbin = None\n",
      "Vis_ret.title = title\n",
      "Vis_ret.score = score\n",
      "\n",
      "# Vis.refresh_source(self_____init__, self_____init__._source)\n",
      "\"\"\"    Loading the source data into the Vis by instantiating the specification and\"\"\"\n",
      "\n",
      "# Vis.check_not_vislist_intent(Vis_ret)\n",
      "\n",
      "syntaxMsg = (\n",
      "    \"The intent that you specified corresponds to more than one visualization. \"\n",
      "    \"Please replace the Vis constructor with VisList to generate a list of visualizations. \"\n",
      "    \"For more information, see: https://lux-api.readthedocs.io/en/latest/source/guide/vis.html#working-with-collections-of-visualization-with-vislist\"\n",
      ")\n",
      "\n",
      "# LuxDataFrame.maintain_metadata(Vis_ret._source)\n",
      "# Check that metadata has not yet been computed\n",
      "Vis_ret._source = Vis_ret._source\n",
      "Vis_ret._inferred_intent = Parser.parse(Vis_ret._intent)\n",
      "\n",
      "# Validator.validate_intent(Vis_ret._inferred_intent, Vis_ret._source)\n",
      "\"\"\"    Validates input specifications from the user to find inconsistencies and errors.\"\"\"\n",
      "\n",
      "for clause in Vis_ret._inferred_intent:\n",
      "\n",
      "    # validate_clause(clause)\n",
      "    warn_msg = \"\"\n",
      "    warn_msg += warn_msg\n",
      "\n",
      "# Compiler.compile_vis(Vis_ret._source, Vis_ret)\n",
      "\"\"\"    Root method for compiling visualizations\"\"\"\n",
      "# autofill data type/model information\n",
      "\n",
      "# Compiler.populate_data_type_model(Vis_ret._source, [Vis_ret])\n",
      "vlist = [Vis_ret]\n",
      "\"\"\"    Given a underspecified Clause, populate the data_type and data_model information accordingly\"\"\"\n",
      "# TODO: copy might not be neccesary\n",
      "\n",
      "for vis in vlist:\n",
      "    for clause in vis._inferred_intent:\n",
      "        # TODO: Note that \"and not is_datetime_string(clause.attribute))\" is a temporary hack and breaks the `test_row_column_group` example\n",
      "        # and not is_datetime_string(clause.attribute):\n",
      "        clause.data_type = Vis_ret._source.data_type_lookup[clause.attribute]\n",
      "        clause.data_model = Vis_ret._source.data_model_lookup[clause.attribute]\n",
      "# remove invalid visualizations from collection\n",
      "\n",
      "# Compiler.remove_all_invalid([Vis_ret])\n",
      "vis_collection = [Vis_ret]\n",
      "\"\"\"    Given an expanded vis list, remove all visualizations that are invalid.\"\"\"\n",
      "new_vc = []\n",
      "for vis in vis_collection:\n",
      "    attribute_set = set()\n",
      "    for clause in vis._inferred_intent:\n",
      "        attribute_set.add(clause.attribute)\n",
      "    all_distinct_specs = 0 == len(vis._inferred_intent) - len(attribute_set)\n",
      "    new_vc.append(vis)\n",
      "    # else:\n",
      "    # \twarnings.warn(\"\\nThere is more than one duplicate attribute specified in the intent.\\nPlease check your intent specification again.\")\n",
      "\n",
      "# VisList(VisList_ret, new_vc)\n",
      "# Overloaded Constructor\n",
      "\n",
      "# VisList.refresh_source(VisList_ret, VisList_ret._source)\n",
      "\"\"\"    Loading the source into the visualizations in the VisList, then populating each visualization\"\"\"\n",
      "warnings.formatwarning = lux.warning_format\n",
      "# autofill viz related information\n",
      "\n",
      "# Compiler.determine_encoding(Vis_ret._source, Vis_ret)\n",
      "vis = Vis_ret\n",
      "\"\"\"    Populates Vis with the appropriate mark type and channel information based on ShowMe logic\"\"\"\n",
      "# Count number of measures and dimensions\n",
      "nmsr = 0\n",
      "filters = []\n",
      "for clause in vis._inferred_intent:\n",
      "    nmsr += 1\n",
      "\n",
      "    # ShowMe logic + additional heuristics\n",
      "    # count_col = Clause( attribute=\"count()\", data_model=\"measure\")\n",
      "Clause_ret = Clause.__new__(Clause)\n",
      "\n",
      "# Clause(\n",
      "#     Clause_ret, attribute=\"Record\",\n",
      "#     aggregation=\"count\",\n",
      "#     data_model=\"measure\",\n",
      "#     data_type=\"quantitative\",\n",
      "# )\n",
      "description = \"\"\n",
      "attribute = \"Record\"\n",
      "value = \"\"\n",
      "filter_op = \"=\"\n",
      "channel = \"\"\n",
      "data_type = \"quantitative\"\n",
      "data_model = \"measure\"\n",
      "aggregation = \"count\"\n",
      "bin_size = 0\n",
      "weight = 1\n",
      "sort = \"\"\n",
      "exclude = \"\"\n",
      "\"\"\"    Parameters\"\"\"\n",
      "# Descriptor\n",
      "Clause_ret.description = description\n",
      "# Description gets compiled to attribute, value, filter_op\n",
      "Clause_ret.attribute = attribute\n",
      "Clause_ret.value = value\n",
      "Clause_ret.filter_op = filter_op\n",
      "# self.parseDescription()\n",
      "# Properties\n",
      "Clause_ret.channel = channel\n",
      "Clause_ret.data_type = data_type\n",
      "Clause_ret.data_model = data_model\n",
      "\n",
      "# Clause.set_aggregation(Clause_ret, aggregation_____init___2)\n",
      "\"\"\"    Sets the aggregation function of Clause,\"\"\"\n",
      "Clause_ret.aggregation = aggregation\n",
      "Clause_ret._aggregation_name = Clause_ret.aggregation\n",
      "Clause_ret.bin_size = bin_size\n",
      "Clause_ret.weight = weight\n",
      "Clause_ret.sort = sort\n",
      "Clause_ret.exclude = exclude\n",
      "auto_channel = {}\n",
      "# Histogram with Count\n",
      "\n",
      "# Vis.get_attr_by_data_model(vis___determine_encoding, \"measure\", exclude_record=True)\n",
      "dmodel = \"measure\"\n",
      "get_attr_by_data_model_ret = list(\n",
      "    filter(\n",
      "        lambda x: x.data_model == dmodel and x.value == \"\"\n",
      "        if x.attribute != \"Record\" and hasattr(x, \"data_model\")\n",
      "        else False,\n",
      "        vis._inferred_intent,\n",
      "    )\n",
      ")\n",
      "measure = get_attr_by_data_model_ret[0]\n",
      "# If no bin specified, then default as 10\n",
      "measure.bin_size = 10\n",
      "auto_channel = {\"x\": measure, \"y\": Clause_ret}\n",
      "vis._mark = \"histogram\"\n",
      "relevant_attributes = [auto_channel[channel].attribute for channel in auto_channel]\n",
      "relevant_min_max = dict(\n",
      "    (attr, Vis_ret._source._min_max[attr])\n",
      "    for attr in relevant_attributes\n",
      "    if attr != \"Record\" and attr in Vis_ret._source._min_max\n",
      ")\n",
      "vis._min_max = relevant_min_max\n",
      "\n",
      "# Compiler.enforce_specified_channel(vis___determine_encoding, auto_channel)\n",
      "\"\"\"    Enforces that the channels specified in the Vis by users overrides the showMe autoChannels.\"\"\"\n",
      "# result of enforcing specified channel will be stored in result_dict\n",
      "result_dict = {}\n",
      "# specified_dict={\"x\":[],\"y\":[list of Dobj with y specified as channel]}\n",
      "specified_dict = {}\n",
      "# create a dictionary of specified channels in the given dobj\n",
      "for val in auto_channel.keys():\n",
      "\n",
      "    # Vis.get_attr_by_channel(vis___determine_encoding, val)\n",
      "    spec_obj = list(\n",
      "        filter(\n",
      "            lambda x: x.channel == val and x.value == \"\" if hasattr(x, \"channel\") else False,\n",
      "            vis._inferred_intent,\n",
      "        )\n",
      "    )\n",
      "    specified_dict[val] = spec_obj\n",
      "    result_dict[val] = \"\"\n",
      "# for every element, replace with what's in specified_dict if specified\n",
      "    # For the leftover channels that are still unspecified in result_dict,\n",
      "    # and the leftovers in the auto_channel specification,\n",
      "    # step through them together and fill it automatically.\n",
      "leftover_channels = list(filter(lambda x: result_dict[x] == \"\", result_dict))\n",
      "for leftover_channel, leftover_encoding in zip(leftover_channels, auto_channel.values()):\n",
      "    leftover_encoding.channel = leftover_channel\n",
      "    result_dict[leftover_channel] = leftover_encoding\n",
      "vis._inferred_intent = list(result_dict.values())\n",
      "vis = vis\n",
      "vis._inferred_intent.extend(filters)  # add back the preserved filters\n",
      "Vis_ret._source._compiled = True\n",
      "\n",
      "# Vis_ret._source.executor.execute([Vis_ret], Vis_ret._source)\n",
      "vislist = [Vis_ret]\n",
      "\"\"\"    Given a VisList, fetch the data required to render the vis.\"\"\"\n",
      "\n",
      "# PandasExecutor.execute_sampling(Vis_ret._source)\n",
      "# General Sampling for entire dataframe\n",
      "Vis_ret._source._sampled = Vis_ret._source\n",
      "for vis in vislist:\n",
      "    # The vis data starts off being original or sampled dataframe\n",
      "    vis._vis_data = Vis_ret._source._sampled\n",
      "\n",
      "    # PandasExecutor.execute_filter(vis)\n",
      "\n",
      "    # Vis.data_getter(vis)\n",
      "    assert (\n",
      "        vis._vis_data is not None\n",
      "    ), \"execute_filter assumes input vis.data is populated (if not, populate with LuxDataFrame values)\"\n",
      "\n",
      "    # utils.get_filter_specs(vis._inferred_intent)\n",
      "    spec_obj = list(filter(lambda x: x.value != \"\", vis._inferred_intent))\n",
      "    # Select relevant data based on attribute information\n",
      "    attributes = set([])\n",
      "    for clause in vis._inferred_intent:\n",
      "        if clause.attribute != \"Record\":\n",
      "            attributes.add(clause.attribute)\n",
      "        # TODO: Add some type of cap size on Nrows ?\n",
      "    vis._vis_data = vis.data[list(attributes)]\n",
      "\n",
      "    # PandasExecutor.execute_binning(vis)\n",
      "    \"\"\"    Binning of data points for generating histograms\"\"\"\n",
      "\n",
      "    bin_attribute = list(filter(lambda x: x.bin_size != 0, vis._inferred_intent))[0]\n",
      "    # np.histogram breaks if array contain NaN\n",
      "\n",
      "    # Vis.data_getter(vis)\n",
      "    series = vis._vis_data[bin_attribute.attribute].dropna()\n",
      "    # TODO:binning runs for name attribte. Name attribute has datatype quantitative which is wrong.\n",
      "    counts, bin_edges = np.histogram(series, bins=bin_attribute.bin_size)\n",
      "    # bin_edges of size N+1, so need to compute bin_center as the bin location\n",
      "    bin_center = np.mean(np.vstack([bin_edges[0:-1], bin_edges[1:]]), axis=0)\n",
      "    # TODO: Should vis.data be a LuxDataFrame or a Pandas DataFrame?\n",
      "    binned_result = np.array([bin_center, counts]).T\n",
      "    vis._vis_data = pd.DataFrame(binned_result, columns=[bin_attribute.attribute, \"Number of Records\"])\n"
     ]
    }
   ],
   "source": [
    "def prog():\n",
    "    Vis(['sepal_length'], iris)\n",
    "    #y = test.A(flag=True)\n",
    "    #assert y.foo(1) == 2\n",
    "    \n",
    "i = Inliner(prog)\n",
    "i.add_target(make_target(lux))\n",
    "\n",
    "i.run_pass('inline')\n",
    "#print(i.code())\n",
    "#print('='*30 + '\\n')\n",
    "\n",
    "i.optimize()\n",
    "print(i.code())\n",
    "#print('='*30 + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T20:05:29.912677Z",
     "start_time": "2019-12-11T20:05:28.943407Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_plot():\n",
    "    import seaborn as sns\n",
    "    iris = sns.load_dataset('iris')\n",
    "    sns.boxplot(x=iris.species, y=iris.petal_length)\n",
    "\n",
    "make_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T20:58:51.463963Z",
     "start_time": "2019-12-11T20:58:24.526791Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inliner = Inliner(make_plot, ['seaborn.categorical'])\n",
    "\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "\n",
    "inliner.copy_propagation()\n",
    "\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "inliner.fixpoint(inliner.deadcode)\n",
    "inliner.inline()\n",
    "\n",
    "inliner.expand_self()\n",
    "inliner.fixpoint(inliner.unread_vars)\n",
    "\n",
    "inliner.copy_propagation()\n",
    "inliner.lifetimes()\n",
    "inliner.copy_propagation()\n",
    "inliner.lifetimes()\n",
    "\n",
    "inliner.expand_tuples()\n",
    "\n",
    "inliner.lifetimes()\n",
    "inliner.lifetimes()\n",
    "\n",
    "inliner.copy_propagation()\n",
    "inliner.lifetimes()\n",
    "\n",
    "inliner.clean_imports()\n",
    "inliner.remove_suffixes()\n",
    "\n",
    "print(inliner.make_program(comments=True))\n",
    "globls = {}\n",
    "exec(inliner.make_program(), globls, globls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
